import time
import asyncio
import os
import json
import shutil
import random
import re
from typing import AsyncGenerator, List, Dict
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI

app = FastAPI()

# Enable CORS for Next.js frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(BASE_DIR, "assets")
OUTPUTS_DIR = os.path.join(BASE_DIR, "outputs")
CONFIG_PATH = os.path.join(BASE_DIR, "config.json")

if not os.path.exists(OUTPUTS_DIR):
    os.makedirs(OUTPUTS_DIR)

# Config helpers
def load_config():
    if os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"openai_api_key": "", "comfyui_path": "", "prompts": {}}

def save_config(config):
    with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=4)

def get_openai_client():
    """Get OpenAI client with API key from config"""
    config = load_config()
    api_key = config.get("openai_api_key", "")
    if not api_key:
        return None
    return OpenAI(api_key=api_key)

# Serve assets & outputs
app.mount("/assets", StaticFiles(directory=ASSETS_DIR), name="assets")
app.mount("/outputs", StaticFiles(directory=OUTPUTS_DIR), name="outputs")

# ==========================================
# [Mock Data] Multi-Step Workflow
# ==========================================
CATEGORIES = ["ì‚¬ê³ ", "ìì—°ì¬í•´", "ë³´ì€", "ë¯¸ìŠ¤í„°ë¦¬", "ì„œë°”ì´ë²Œ", "ë¡œë§¨ìŠ¤", "ìš°ì •", "ë³µìˆ˜", "ì„±ì¥", "ëª¨í—˜"]

MOCK_DRAFTS = {
    "ì‚¬ê³ ": [
        {"id": 1, "title": "The Last Witness", "summary": "ì´ë¥¸ ì•„ì¹¨ ì¶œê·¼ê¸¸, í•œ ì—¬ì„±ì´ ë”ì°í•œ êµí†µì‚¬ê³ ë¥¼ ëª©ê²©í•œë‹¤. ê·¸ë…€ê°€ ë³¸ ê²ƒì€ ë‹¨ìˆœí•œ ì‚¬ê³ ê°€ ì•„ë‹ˆì—ˆë‹¤. ë¸”ë™ë°•ìŠ¤ì— ë‹´ê¸´ ì§„ì‹¤, ê·¸ë¦¬ê³  ì‚¬ë¼ì§„ ìš´ì „ì. ëª¨ë“  ì¦ê±°ê°€ ê·¸ë…€ë¥¼ ê°€ë¦¬í‚¬ ë•Œ, ì§„ì§œ ë²”ì¸ì„ ì°¾ê¸° ìœ„í•œ 48ì‹œê°„ì˜ ì¶”ê²©ì´ ì‹œì‘ëœë‹¤.", "theme": "thriller"},
        {"id": 2, "title": "Broken Promises", "summary": "10ë…„ ì „ ê·¸ë‚ ì˜ ì‚¬ê³ ë¡œ ëª¨ë“  ê²ƒì„ ìƒì€ ë‚¨ì. ê°€í•´ìëŠ” ë²•ì˜ í—ˆì ì„ ì´ìš©í•´ ë¬´ì£„ë¡œ í’€ë ¤ë‚¬ë‹¤. ì´ì œ ê·¸ëŠ” ìŠí˜€ì§„ ì‚¬ê±´ì˜ ì§„ì‹¤ì„ íŒŒí—¤ì¹˜ë©°, ìì‹ ë§Œì˜ ì •ì˜ë¥¼ ì‹¤í˜„í•˜ë ¤ í•œë‹¤. í•˜ì§€ë§Œ ì§„ì‹¤ì€ ê·¸ê°€ ì˜ˆìƒí•œ ê²ƒë³´ë‹¤ í›¨ì”¬ ì”ì¸í–ˆë‹¤.", "theme": "drama"},
        {"id": 3, "title": "Miracle Mile", "summary": "ê³ ì†ë„ë¡œ ìœ„ 100ì¤‘ ì¶”ëŒ ì‚¬ê³ . ê·¸ í˜¼ë€ ì†ì—ì„œ í•œ ì‘ê¸‰êµ¬ì¡°ì‚¬ê°€ ìì‹ ì˜ ëª©ìˆ¨ì„ ê±¸ê³  ìƒì¡´ìë“¤ì„ êµ¬í•´ë‚¸ë‹¤. ëª¨ë‘ê°€ í¬ê¸°í•œ ìˆœê°„, ê·¸ë…€ëŠ” ì™œ ë‹¬ë ¤ë“¤ì—ˆì„ê¹Œ? ì‚¬ê³  í˜„ì¥ì—ì„œ í¼ì³ì§€ëŠ” ì¸ê°„ ë³¸ì„±ì˜ ê·¹í•œ.", "theme": "heroic"},
        {"id": 4, "title": "Chain Reaction", "summary": "í•œ ê±´ì˜ ì‚¬ì†Œí•œ ì ‘ì´‰ ì‚¬ê³ ê°€ ë„ì‹œ ì „ì²´ë¥¼ ë§ˆë¹„ì‹œí‚¨ë‹¤. ì—°ì‡„ì ìœ¼ë¡œ ì¼ì–´ë‚˜ëŠ” ì‚¬ê±´ë“¤, ê·¸ë¦¬ê³  ìš°ì—°íˆ ì–½íŒ ë‹¤ì„¯ ì‚¬ëŒì˜ ìš´ëª…. ê·¸ë“¤ì€ ì„œë¡œë¥¼ êµ¬í•  ìˆ˜ ìˆì„ê¹Œ, ì•„ë‹ˆë©´ í•¨ê»˜ ì¶”ë½í•  ê²ƒì¸ê°€?", "theme": "ensemble"},
        {"id": 5, "title": "The Survivor", "summary": "í•´ì € í„°ë„ ë¶•ê´´ ì‚¬ê³ ì—ì„œ í™€ë¡œ ì‚´ì•„ë‚¨ì€ ì²­ë…„. íŠ¸ë¼ìš°ë§ˆì™€ ìƒì¡´ì ì£„ì±…ê°ì— ì‹œë‹¬ë¦¬ë˜ ê·¸ì—ê²Œ í•œ í†µì˜ ì „í™”ê°€ ê±¸ë ¤ì˜¨ë‹¤. 'ë‹¹ì‹ ì´ ì‚´ì•„ë‚¨ì€ ê±´ ìš°ì—°ì´ ì•„ë‹™ë‹ˆë‹¤.' ì‚¬ê³ ì˜ ì§„ì§œ ì›ì¸ì„ ì¶”ì í•˜ëŠ” ê·¸ì˜ ìœ„í—˜í•œ ì—¬ì •.", "theme": "mystery"},
        {"id": 6, "title": "Intersection", "summary": "ê°™ì€ êµì°¨ë¡œ, ê°™ì€ ì‹œê°„, ë‹¤ë¥¸ ì¸ìƒ. êµí†µì‚¬ê³ ë¡œ ë§Œë‚œ ë‘ ì‚¬ëŒì´ ì„œë¡œì˜ ì‚¶ì„ ë°”ê¿”ë†“ëŠ”ë‹¤. ê°€í•´ìì™€ í”¼í•´ì, ê·¸ ê²½ê³„ê°€ ë¬´ë„ˆì§ˆ ë•Œ ë‚¨ëŠ” ê²ƒì€ ë¬´ì—‡ì¼ê¹Œ? ìš©ì„œì™€ ì†ì£„ì— ê´€í•œ ê¹Šì€ ì´ì•¼ê¸°.", "theme": "emotional"},
        {"id": 7, "title": "Impact Zone", "summary": "í•­ê³µê¸° ì¶”ë½ ì‚¬ê³  í˜„ì¥. ìƒì¡´ìëŠ” ì—†ë‹¤ê³  ë°œí‘œë˜ì—ˆì§€ë§Œ, í•œ ê¸°ìê°€ ì”í•´ ì†ì—ì„œ ì´ìƒí•œ ì ì„ ë°œê²¬í•œë‹¤. ë¸”ë™ë°•ìŠ¤ê°€ ì¡°ì‘ë˜ì—ˆë‹¤? ì€íëœ ì§„ì‹¤ì„ íŒŒí—¤ì¹˜ëŠ” íƒì‚¬ë³´ë„ì˜ ì—¬ì •.", "theme": "investigative"},
        {"id": 8, "title": "Second Chance", "summary": "ìŒì£¼ìš´ì „ ì‚¬ê³ ë¡œ íƒ€ì¸ì˜ ì‚¶ì„ ë§ì¹œ ë‚¨ì. 5ë…„ì˜ ë³µì—­ í›„ ì¶œì†Œí•œ ê·¸ëŠ” í”¼í•´ì ê°€ì¡±ì„ ì°¾ì•„ê°„ë‹¤. ìš©ì„œë°›ì„ ìˆ˜ ì—†ëŠ” ì£„, ê·¸ëŸ¼ì—ë„ ì†ì£„ì˜ ê¸¸ì„ ê±·ëŠ” í•œ ì¸ê°„ì˜ ê³ í†µìŠ¤ëŸ¬ìš´ ì—¬ì •.", "theme": "redemption"},
        {"id": 9, "title": "Edge of Impact", "summary": "ìŠ¤í„´íŠ¸ë§¨ìœ¼ë¡œ ì‚´ì•„ì˜¨ ê·¸ì—ê²Œ ì‚¬ê³ ëŠ” ì¼ìƒì´ì—ˆë‹¤. í•˜ì§€ë§Œ ì´ë²ˆ ì‚¬ê³ ëŠ” ë‹¬ëë‹¤. ì¹´ë©”ë¼ ì•ì—ì„œ ì¼ì–´ë‚œ 'ì‚¬ê³ 'ëŠ” ê³„íšëœ ì‚´ì¸ì´ì—ˆë‹¤. ì§„ì‹¤ì„ ì¦ëª…í•  ìˆ˜ ìˆëŠ” ê±´ ì˜¤ì§ ê·¸ì˜ ê¸°ì–µë¿.", "theme": "action"},
        {"id": 10, "title": "After the Crash", "summary": "ìŠ¤ì¿¨ë²„ìŠ¤ ì „ë³µ ì‚¬ê³ ì—ì„œ ì•„ì´ë“¤ì„ ëª¨ë‘ êµ¬í•œ ì Šì€ êµì‚¬. ì˜ì›…ìœ¼ë¡œ ì¹­ì†¡ë°›ì§€ë§Œ, ê·¸ë…€ì˜ ë§ˆìŒì†ì—ëŠ” êµ¬í•˜ì§€ ëª»í•œ ë‹¨ í•œ ëª…ì˜ ì–¼êµ´ì´ ì‚¬ë¼ì§€ì§€ ì•ŠëŠ”ë‹¤. ì£„ì±…ê°ê³¼ íŠ¸ë¼ìš°ë§ˆë¥¼ ê·¹ë³µí•˜ëŠ” ì¹˜ìœ ì˜ ì´ì•¼ê¸°.", "theme": "healing"}
    ],
    "ìì—°ì¬í•´": [
        {"id": 1, "title": "The Day Earth Shook", "summary": "ê·œëª¨ 9.1 ì´ˆëŒ€í˜• ì§€ì§„ì´ ë„ì‹œë¥¼ ë®ì¹œë‹¤. ë¬´ë„ˆì§„ ë¹Œë”© ì”í•´ ì†, ì—˜ë¦¬ë² ì´í„°ì— ê°‡íŒ ë‹¤ì„¯ ì‚¬ëŒì˜ 72ì‹œê°„ ìƒì¡´ê¸°. ê·¸ë“¤ì€ ì„œë¡œê°€ ìœ ì¼í•œ í¬ë§ì´ë‹¤.", "theme": "survival"},
        {"id": 2, "title": "Rising Waters", "summary": "ê¸°ë¡ì ì¸ í­ìš°ê°€ ë§ˆì„ì„ ì‚¼í‚¨ë‹¤. ê³ ë¦½ëœ ì‘ì€ ë§ˆì„ì—ì„œ ì£¼ë¯¼ë“¤ì€ í˜ì„ í•©ì³ ì‚´ì•„ë‚¨ì•„ì•¼ í•œë‹¤. ë¬¼ì´ ì°¨ì˜¤ë¥´ëŠ” ì†ë„ë³´ë‹¤ ë¹ ë¥´ê²Œ, ê·¸ë“¤ì˜ ì—°ëŒ€ë„ ì»¤ì ¸ê°„ë‹¤.", "theme": "community"},
        {"id": 3, "title": "Eye of the Storm", "summary": "ì¹´í…Œê³ ë¦¬ 5 í—ˆë¦¬ì¼€ì¸ì´ ì ‘ê·¼ ì¤‘. ëŒ€í”¼ ëª…ë ¹ì„ ë¬´ì‹œí•˜ê³  ë‚¨ì€ í•œ ê¸°ìƒí•™ì. ê·¸ë…€ì—ê²ŒëŠ” í­í’ì˜ ëˆˆì„ ê´€ì¸¡í•´ì•¼ë§Œ í•˜ëŠ” ì´ìœ ê°€ ìˆì—ˆë‹¤.", "theme": "scientific"},
        {"id": 4, "title": "Frozen World", "summary": "ì˜ˆê³  ì—†ì´ ì°¾ì•„ì˜¨ ë¹™í•˜ê¸°. ì˜í•˜ 60ë„ì˜ ê·¹í•œ ì¶”ìœ„ ì†ì—ì„œ ì‚´ì•„ë‚¨ê¸° ìœ„í•œ ê°€ì¡±ì˜ ì‚¬íˆ¬. ë§ˆì§€ë§‰ ë”°ëœ»í•¨ì„ ë‚˜ëˆŒ ìˆ˜ ìˆì„ ê²ƒì¸ê°€.", "theme": "family"},
        {"id": 5, "title": "When Mountains Fall", "summary": "ì‚°ì‚¬íƒœê°€ ë§ˆì„ì„ ë®ì¹œ ê·¸ë‚  ë°¤. êµ¬ì¡°ëŒ€ê°€ ë„ì°©í•˜ê¸° ì „ê¹Œì§€ ë²„í…¨ì•¼ í•˜ëŠ” ìƒì¡´ìë“¤. í™ë”ë¯¸ ì•„ë˜ì—ì„œ ë“¤ë ¤ì˜¤ëŠ” í¬ë¯¸í•œ ëª©ì†Œë¦¬ê°€ ê·¸ë“¤ì„ ì´ëˆë‹¤.", "theme": "rescue"},
        {"id": 6, "title": "The Volcano's Wrath", "summary": "íœ´í™”ì‚°ì´ ê°‘ìê¸° í­ë°œí•œë‹¤. ìš©ì•”ì´ ë§ˆì„ì„ í–¥í•´ í˜ëŸ¬ì˜¤ëŠ” ê°€ìš´ë°, í•œ ì†Œë°©ê´€ì€ ìì‹ ì˜ ëª¨ë“  ê²ƒì„ ê±¸ê³  ì£¼ë¯¼ë“¤ì„ ëŒ€í”¼ì‹œí‚¨ë‹¤.", "theme": "heroic"},
        {"id": 7, "title": "Tsunami Hour", "summary": "í•´ì•ˆê°€ ë¦¬ì¡°íŠ¸ì—ì„œ í–‰ë³µí•œ íœ´ê°€ë¥¼ ë³´ë‚´ë˜ ê°€ì¡±. ê°‘ìê¸° ë°”ë‹¤ê°€ ë¬¼ëŸ¬ê°€ê³ , 30ë¶„ í›„ ê±°ëŒ€í•œ íŒŒë„ê°€ ëª°ë ¤ì˜¨ë‹¤. ìƒì¡´ì„ ìœ„í•œ ì ˆë°•í•œ ì„ íƒì˜ ìˆœê°„ë“¤.", "theme": "disaster"},
        {"id": 8, "title": "Buried Alive", "summary": "ëˆˆì‚¬íƒœì— ë§¤ëª°ëœ ìŠ¤í‚¤ì–´. ëˆˆ ì†ì—ì„œ ë³´ë‚´ëŠ” 8ì‹œê°„, ê·¸ì˜ ë¨¸ë¦¿ì†ì„ ìŠ¤ì³ê°€ëŠ” ì‚¶ì˜ ê¸°ì–µë“¤. ê·¸ë¦¬ê³  êµ¬ì¡°ëŒ€ì˜ ì‚½ ì†Œë¦¬ê°€ ë“¤ë ¤ì˜¬ ë•Œ.", "theme": "introspective"},
        {"id": 9, "title": "Wildfire", "summary": "í†µì œ ë¶ˆëŠ¥ì˜ ì‚°ë¶ˆì´ ìº˜ë¦¬í¬ë‹ˆì•„ë¥¼ ì§‘ì–´ì‚¼í‚¨ë‹¤. ì†Œë°©ê´€ë“¤ì˜ ì‚¬íˆ¬, ê·¸ë¦¬ê³  ëª¨ë“  ê²ƒì„ ìƒì€ ì‚¬ëŒë“¤ì˜ ì¬ê±´ ì´ì•¼ê¸°.", "theme": "devastation"},
        {"id": 10, "title": "After the Quake", "summary": "ì§€ì§„ ì´í›„ 3ì¼ì§¸. ë¬´ë„ˆì§„ ë³‘ì› ì§€í•˜ì— ê°‡íŒ ì˜ì‚¬ì™€ í™˜ìë“¤. ì œí•œëœ ì˜ë£Œí’ˆìœ¼ë¡œ ìƒëª…ì„ ì‚´ë ¤ì•¼ í•˜ëŠ” ê·¹í•œ ìƒí™©.", "theme": "medical"}
    ]
}

# ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬ì— ê¸°ë³¸ ì´ˆì•ˆ ìƒì„±
for cat in CATEGORIES:
    if cat not in MOCK_DRAFTS:
        MOCK_DRAFTS[cat] = [
            {"id": i+1, "title": f"{cat} Story {i+1}", "summary": f"{cat}ë¥¼ ì£¼ì œë¡œ í•œ í¥ë¯¸ì§„ì§„í•œ ì´ì•¼ê¸° #{i+1}. ì˜ˆìƒì¹˜ ëª»í•œ ì „ê°œì™€ ê°ë™ì ì¸ ê²°ë§ì´ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.", "theme": "general"}
            for i in range(10)
        ]

MOCK_TITLES = [
    {"title": "Against All Odds", "style": "impact"},
    {"title": "A Fleeting Hope", "style": "emotional"},
    {"title": "The Great Escape", "style": "impact"},
    {"title": "Whispers in the Rain", "style": "emotional"},
    {"title": "Wild Heart: A Survivor's Tale", "style": "documentary"},
    {"title": "The Urban Survivor", "style": "documentary"},
    {"title": "Breaking Point", "style": "impact"},
    {"title": "Into the Unknown", "style": "emotional"},
    {"title": "Unbreakable Spirit", "style": "impact"},
    {"title": "The Last Stand", "style": "documentary"}
]

# ==========================================
# [API] Settings
# ==========================================

class SettingsUpdate(BaseModel):
    openai_api_key: str | None = None
    comfyui_path: str | None = None
    prompts: dict | None = None

@app.get("/api/settings")
async def get_settings():
    """Get current settings (API key masked)"""
    config = load_config()
    # Mask API key for security
    masked_key = ""
    if config.get("openai_api_key"):
        key = config["openai_api_key"]
        masked_key = key[:8] + "..." + key[-4:] if len(key) > 12 else "****"
    return {
        "openai_api_key_masked": masked_key,
        "openai_api_key_set": bool(config.get("openai_api_key")),
        "comfyui_path": config.get("comfyui_path", ""),
        "prompts": config.get("prompts", {})
    }

@app.put("/api/settings")
async def update_settings(settings: SettingsUpdate):
    """Update settings"""
    config = load_config()
    
    if settings.openai_api_key is not None:
        config["openai_api_key"] = settings.openai_api_key
    if settings.comfyui_path is not None:
        config["comfyui_path"] = settings.comfyui_path
    if settings.prompts is not None:
        config["prompts"] = settings.prompts
    
    save_config(config)
    return {"success": True}

# ==========================================
# [API] Workflow Endpoints
# ==========================================

class DraftRequest(BaseModel):
    mode: str  # "long" or "short"
    category: str | None = None
    customInput: str | None = None

class StoryRequest(BaseModel):
    mode: str
    draftId: int
    draftTitle: str
    draftSummary: str

class UploadRequest(BaseModel):
    image: str # Base64 string
    filename: str

class TitleRequest(BaseModel):
    storyPreview: str

@app.post("/api/workflow/upload_reference")
async def upload_reference(req: UploadRequest):
    """Upload reference image for IP-Adapter"""
    try:
        # Decode base64
        import base64
        image_data = base64.b64decode(req.image.split(",")[1])
        
        # Save locally to assets/temp (just for serving back to frontend if needed)
        # And upload to ComfyUI
        
        # For this implementation, we assume ComfyUI is local or standard API upload
        # If local, we can just save it to ComfyUI input folder if path is known from config
        config = load_config()
        comfy_path = config.get("comfyui_path", "")
        
        if comfy_path and os.path.exists(comfy_path):
            input_dir = os.path.join(comfy_path, "input")
            if not os.path.exists(input_dir):
                os.makedirs(input_dir)
            with open(os.path.join(input_dir, req.filename), "wb") as f:
                f.write(image_data)
            return {"success": True, "path": req.filename, "method": "local_copy"}
        
        # If remote or path not set, use ComfyUI API to upload (TODO: Implement full API upload)
        # For now, just save to local assets so frontend shows it
        temp_path = os.path.join(ASSETS_DIR, req.filename)
        with open(temp_path, "wb") as f:
            f.write(image_data)
            
        return {"success": True, "path": f"/assets/{req.filename}", "method": "temp_server"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/workflow/drafts")
async def generate_drafts(req: DraftRequest):
    """Step 1: Generate 10 story drafts based on category or custom input"""
    config = load_config()
    client = get_openai_client()
    
    # If no API key, use mock data
    if not client:
        await asyncio.sleep(1.5)
        if req.category and req.category in MOCK_DRAFTS:
            drafts = MOCK_DRAFTS[req.category]
        else:
            input_text = req.customInput or "custom story"
            drafts = [
                {"id": i+1, "title": f"Version {i+1}: {input_text[:20]}...", "summary": f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ '{input_text}'ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹¤ì‚¬ ìŠ¤í† ë¦¬ ë²„ì „ {i+1}. AIê°€ ì°½ì˜ì ìœ¼ë¡œ í•´ì„í•˜ì—¬ ë…íŠ¹í•œ ì „ê°œë¥¼ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.", "theme": "custom"}
                for i in range(10)
            ]
        return {"success": True, "drafts": drafts, "source": "mock"}
    
    # Real OpenAI API call
    try:
        system_prompt = config.get("prompts", {}).get("draft_generation", "ë‹¹ì‹ ì€ ì‹¤ì‚¬ ì˜ìƒ ìŠ¤í† ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤. 10ê°€ì§€ ìŠ¤í† ë¦¬ ì´ˆì•ˆì„ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.")
        user_input = req.customInput if req.customInput else f"ì¹´í…Œê³ ë¦¬: {req.category}"
        
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ]
        )
        
        # Parse JSON from response
        output_text = response.output_text
        # Try to extract JSON array from response
        json_match = re.search(r'\[.*\]', output_text, re.DOTALL)
        if json_match:
            drafts = json.loads(json_match.group())
        else:
            drafts = [{"id": 1, "title": "Error parsing response", "summary": output_text[:500], "theme": "error"}]
        
        return {"success": True, "drafts": drafts, "source": "openai"}
    except Exception as e:
        # Fallback to mock on error
        print(f"OpenAI Error: {e}")
        if req.category and req.category in MOCK_DRAFTS:
            drafts = MOCK_DRAFTS[req.category]
        else:
            drafts = [{"id": 1, "title": "API Error", "summary": str(e), "theme": "error"}]
        return {"success": True, "drafts": drafts, "source": "mock_fallback", "error": str(e)}

@app.post("/api/workflow/story")
async def generate_story(req: StoryRequest):
    """Step 2: Generate detailed story cuts and character description"""
    config = load_config()
    client = get_openai_client()
    total_cuts = 100 if req.mode == "long" else 20
    
    # If no API key, use mock data
    if not client:
        await asyncio.sleep(2)
        cuts = []
        cut_descriptions = [
            "ì´ë¥¸ ìƒˆë²½, ì•ˆê°œê°€ ììš±í•œ ë„ë¡œ. í¬ë¯¸í•œ ê°€ë¡œë“± ë¶ˆë¹› ì•„ë˜ í•œ ì—¬ì„±ì´ ê±¸ì–´ê°„ë‹¤.",
            "ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì¶©ëŒìŒ. ê·¸ë…€ì˜ ëˆˆì´ ì»¤ì§€ë©° ê³ ê°œë¥¼ ëŒë¦°ë‹¤.",
            "ì‚¬ê³  í˜„ì¥. ë’¤í‹€ë¦° ê¸ˆì†ê³¼ í©ì–´ì§„ ìœ ë¦¬ íŒŒí¸ë“¤.",
            "ë–¨ë¦¬ëŠ” ì†ìœ¼ë¡œ íœ´ëŒ€í°ì„ êº¼ë‚´ëŠ” ê·¸ë…€. 119ë¥¼ ëˆ„ë¥´ì§€ë§Œ ì†ê°€ë½ì´ êµ³ì–´ë²„ë¦°ë‹¤.",
            "ë©€ë¦¬ì„œ ë‹¤ê°€ì˜¤ëŠ” ì¸ì˜. ëˆ„êµ°ê°€ ì‚¬ê³  í˜„ì¥ì„ ë– ë‚˜ê³  ìˆë‹¤.",
        ]
        for i in range(1, total_cuts + 1):
            cuts.append({"cutNumber": i, "description": cut_descriptions[(i - 1) % len(cut_descriptions)] + f" (ì»· {i})"})
        
        character_prompt = "[Mock] ë©”ì¸ ìºë¦­í„° - 30ëŒ€ ì´ˆë°˜ í•œêµ­ì¸ ì—¬ì„±, ë‹¨ë°œ ë¨¸ë¦¬"
        return {"success": True, "totalCuts": total_cuts, "cuts": cuts, "characterPrompt": character_prompt, "source": "mock"}
    
    # Real OpenAI API call
    try:
        system_prompt = config.get("prompts", {}).get("story_confirmation", "")
        if not system_prompt:
            system_prompt = f"ë‹¹ì‹ ì€ ì˜ìƒ ì œì‘ ì „ë¬¸ ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ì…ë‹ˆë‹¤. {total_cuts}ì»·ì˜ ìƒì„¸ ìŠ¤í† ë¦¬ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”."
        else:
            system_prompt = system_prompt.replace("{cuts}", str(total_cuts))
        
        user_input = f"ì œëª©: {req.draftTitle}\n\nì´ˆì•ˆ ìš”ì•½:\n{req.draftSummary}\n\nìœ„ ì´ˆì•ˆì„ ë°”íƒ•ìœ¼ë¡œ {total_cuts}ì»·ì˜ ìƒì„¸ ìŠ¤í† ë¦¬ì™€ ìºë¦­í„° ë¬˜ì‚¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ]
        )
        
        output_text = response.output_text
        
        # Try to parse JSON
        json_match = re.search(r'\{.*\}', output_text, re.DOTALL)
        if json_match:
            parsed = json.loads(json_match.group())
            cuts = parsed.get("cuts", [])
            character_prompt = parsed.get("characterPrompt", "ìºë¦­í„° ì •ë³´ ì—†ìŒ")
        else:
            # Fallback: create simple cuts from text
            lines = output_text.split('\n')
            cuts = [{"cutNumber": i+1, "description": line[:200]} for i, line in enumerate(lines[:total_cuts]) if line.strip()]
            character_prompt = "ì‘ë‹µì—ì„œ ìºë¦­í„° ì •ë³´ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        return {"success": True, "totalCuts": total_cuts, "cuts": cuts, "characterPrompt": character_prompt, "source": "openai"}
    except Exception as e:
        print(f"OpenAI Story Error: {e}")
        cuts = [{"cutNumber": 1, "description": f"API ì˜¤ë¥˜: {str(e)}"}]
        return {"success": True, "totalCuts": 1, "cuts": cuts, "characterPrompt": str(e), "source": "error"}

@app.post("/api/workflow/titles")
async def generate_titles(req: TitleRequest):
    """Step 4: Generate native English title suggestions"""
    config = load_config()
    client = get_openai_client()
    
    # If no API key, use mock data
    if not client:
        await asyncio.sleep(1)
        shuffled = random.sample(MOCK_TITLES, min(len(MOCK_TITLES), 8))
        return {"success": True, "titles": shuffled, "source": "mock"}
    
    # Real OpenAI API call
    try:
        system_prompt = config.get("prompts", {}).get("title_generation", "ì˜ë¯¸ê¶Œ ì½˜í…ì¸  ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìŠ¤í† ë¦¬ ë¶„ì„ í›„ ì˜ì–´ ì œëª© 8ê°œë¥¼ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.")
        
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ìŠ¤í† ë¦¬ì— ì–´ìš¸ë¦¬ëŠ” ì˜ì–´ ì œëª©ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n{req.storyPreview}"}
            ]
        )
        
        output_text = response.output_text
        
        json_match = re.search(r'\[.*\]', output_text, re.DOTALL)
        if json_match:
            titles = json.loads(json_match.group())
        else:
            # Fallback: extract titles from text
            lines = [line.strip() for line in output_text.split('\n') if line.strip()]
            titles = [{"title": line[:50], "style": "general"} for line in lines[:8]]
        
        return {"success": True, "titles": titles, "source": "openai"}
    except Exception as e:
        print(f"OpenAI Titles Error: {e}")
        shuffled = random.sample(MOCK_TITLES, min(len(MOCK_TITLES), 8))
        return {"success": True, "titles": shuffled, "source": "mock_fallback", "error": str(e)}

# ==========================================
# [Core Logic] Parameter Calculator
# ==========================================
def calculate_parameters(mode: str, concept: str, cuts: int, selected_title: str = ""):
    params = {
        "resolution_w": 1920 if mode == "Long Form (16:9)" else 1080,
        "resolution_h": 1080 if mode == "Long Form (16:9)" else 1920,
        "mode_name": "LONG_FORM" if mode == "Long Form (16:9)" else "SHORT_FORM",
        "total_cuts": cuts,
        "concept": concept,
        "image_filename": "korean_woman_wide.png" if mode == "Long Form (16:9)" else "korean_woman_tall.png",
        "selected_title": selected_title
    }
    
    if concept == "ëŒ€ì„œì‚¬ì‹œ (Epic)":
        params["batch_loop_count"] = 5
        params["cut_instruction"] = f"{cuts}ì»·ì˜ ì›…ì¥í•œ ì„œì‚¬ì‹œ ìƒì„±"
    elif concept == "ë°”ì´ëŸ´ (Viral)":
        params["batch_loop_count"] = 2
        params["cut_instruction"] = f"{cuts}ì»·ì˜ íŠ¸ë Œë””í•˜ê³  ë¹ ë¥¸ í…œí¬ ë°”ì´ëŸ´ ë¹„ë””ì˜¤ ìƒì„±"
    else:
        params["batch_loop_count"] = 3
        params["cut_instruction"] = f"{cuts}ì»·ì˜ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìƒì„±"

    return params

# ==========================================
# [API] History
# ==========================================
@app.get("/api/history")
async def get_history():
    history = []
    if not os.path.exists(OUTPUTS_DIR):
        return []
    
    folders = sorted(os.listdir(OUTPUTS_DIR), reverse=True)
    for folder_name in folders:
        folder_path = os.path.join(OUTPUTS_DIR, folder_name)
        if os.path.isdir(folder_path):
            images = sorted([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg'))])
            meta_path = os.path.join(folder_path, "metadata.json")
            
            title = folder_name
            mode = "Unknown"
            timestamp = folder_name.split('_')[0] if '_' in folder_name else ""
            stats = {"cuts": 0}
            
            if os.path.exists(meta_path):
                try:
                    with open(meta_path, 'r') as f:
                        meta = json.load(f)
                        title = meta.get("title", title)
                        mode = meta.get("mode", mode)
                        stats["cuts"] = meta.get("cuts", len(images))
                except:
                    pass
            
            thumbnails = [f"/outputs/{folder_name}/{img}" for img in images[:3]]
            
            history.append({
                "id": folder_name,
                "title": title,
                "mode": mode,
                "timestamp": timestamp,
                "thumbnails": thumbnails,
                "folder_name": folder_name,
                "image_count": stats["cuts"]
            })
    return history

@app.get("/api/history/{folder_name}")
async def get_project_details(folder_name: str):
    folder_path = os.path.join(OUTPUTS_DIR, folder_name)
    if not os.path.exists(folder_path):
        return {"error": "Not found"}
    
    images = sorted([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg'))])
    meta_path = os.path.join(folder_path, "metadata.json")
    meta = {}
    if os.path.exists(meta_path):
        with open(meta_path, 'r') as f:
            meta = json.load(f)
            
    return {
        "title": meta.get("title", folder_name),
        "assets": [f"/outputs/{folder_name}/{img}" for img in images],
        "metadata": meta
    }

@app.delete("/api/history/{folder_name}")
async def delete_history(folder_name: str):
    folder_path = os.path.join(OUTPUTS_DIR, folder_name)
    if os.path.exists(folder_path) and os.path.isdir(folder_path):
        abs_outputs = os.path.abspath(OUTPUTS_DIR)
        abs_target = os.path.abspath(folder_path)
        if not abs_target.startswith(abs_outputs):
            return {"success": False, "error": "Invalid path"}
        shutil.rmtree(folder_path)
        return {"success": True}
    return {"success": False, "error": "Folder not found"}

# ==========================================
# [Mock Generator] SSE Stream
# ==========================================
async def mock_comfyui_process_generator(params: dict, topic: str) -> AsyncGenerator[str, None]:
    def create_sse_event(data: dict):
        return f"data: {json.dumps(data)}\n\n"

    def get_time():
        return time.strftime("%H:%M:%S")

    yield create_sse_event({"type": "log", "message": f"[{get_time()}] ğŸš€ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” (ì»¨ì…‰: {params['concept']})..."})
    await asyncio.sleep(0.5)

    timestamp = time.strftime("%Y%m%d-%H%M%S")
    title_to_use = params.get("selected_title", topic[:20]) if params.get("selected_title") else (topic[:20] if topic else "Untitled_Project")
    folder_name = f"{timestamp}_{title_to_use.replace(' ', '_').replace(':', '')}"
    project_dir = os.path.join(OUTPUTS_DIR, folder_name)
    os.makedirs(project_dir, exist_ok=True)

    total_cuts = params['total_cuts']
    yield create_sse_event({"type": "log", "message": f"[{get_time()}] ğŸ“ [Step 2] {total_cuts}ì»· ë§¤í•‘ ë° íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ."})
    
    src_img = os.path.join(ASSETS_DIR, params['image_filename'])
    
    for i in range(1, total_cuts + 1):
        if i % 10 == 0 or i == 1 or i == total_cuts:
            yield create_sse_event({"type": "log", "message": f"[{get_time()}] ğŸ¨ [Asset Gen] Cut #{i}/{total_cuts} ìƒì„± ì¤‘..."})
            await asyncio.sleep(0.1)
        
        dest_filename = f"cut_{i:03d}.png"
        if os.path.exists(src_img):
            shutil.copy(src_img, os.path.join(project_dir, dest_filename))

    result_data = {
        "image_url": f"http://localhost:3501/outputs/{folder_name}/cut_001.png",
        "title": title_to_use,
        "mode": params["mode_name"],
        "cuts": total_cuts,
        "concept": params["concept"],
        "resolution": f"{params['resolution_w']}x{params['resolution_h']}"
    }
    
    with open(os.path.join(project_dir, "metadata.json"), 'w') as f:
        json.dump(result_data, f)

    yield create_sse_event({"type": "log", "message": f"[{get_time()}] âœ… [ì™„ë£Œ] {total_cuts}ê°œ ì´ë¯¸ì§€ íŒŒì¼ì´ '{folder_name}' ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."})
    yield create_sse_event({"type": "result", "data": result_data})
    yield create_sse_event({"type": "done"})

@app.get("/api/stream")
async def stream_workflow(mode: str, topic: str, cuts: int = 20, concept: str = "ê¸°ë³¸ (Default)", title: str = ""):
    params = calculate_parameters(mode, concept, cuts, title)
    return StreamingResponse(
        mock_comfyui_process_generator(params, topic), 
        media_type="text/event-stream"
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=3501)
